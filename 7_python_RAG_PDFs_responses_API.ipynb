{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install PyPDF2 pandas tqdm openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (1.66.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import concurrent\n",
    "import PyPDF2\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "XAI API Key exists and begins xai-fDAl\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "xai_api_key = os.getenv('XAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "\n",
    "\n",
    "if xai_api_key:\n",
    "    print(f\"XAI API Key exists and begins {xai_api_key[:8]}\")\n",
    "else:    \n",
    "    print(\"XAI API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 PDF files to process\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "#despite Grok using same SDK as OpenAI it seems ResponsesAPI is not available. Leaving here \n",
    "# in case situation changes :D\n",
    "# client = OpenAI(\n",
    "#     api_key=xai_api_key,\n",
    "#     base_url=\"https://api.x.ai/v1\",\n",
    "# )\n",
    "dir_pdfs = 'mediterranean_noir_pdfs' # have those PDFs stored locally here\n",
    "pdf_files = [os.path.join(dir_pdfs, f) for f in os.listdir(dir_pdfs)]\n",
    "\n",
    "print(f\"{len(pdf_files)} PDF files to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_single_pdf(file_path: str, vector_store_id: str):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    try:\n",
    "        file_response = client.files.create(file=open(file_path, 'rb'), purpose=\"assistants\")\n",
    "        attach_response = client.vector_stores.files.create(\n",
    "            vector_store_id=vector_store_id,\n",
    "            file_id=file_response.id\n",
    "        )\n",
    "        return {\"file\": file_name, \"status\": \"success\"}\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {file_name}: {str(e)}\")\n",
    "        return {\"file\": file_name, \"status\": \"failed\", \"error\": str(e)}\n",
    "\n",
    "def upload_pdf_files_to_vector_store(vector_store_id: str):\n",
    "    pdf_files = [os.path.join(dir_pdfs, f) for f in os.listdir(dir_pdfs)]\n",
    "    stats = {\"total_files\": len(pdf_files), \"successful_uploads\": 0, \"failed_uploads\": 0, \"errors\": []}\n",
    "    \n",
    "    print(f\"{len(pdf_files)} PDF files to process. Uploading in parallel...\")\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {executor.submit(upload_single_pdf, file_path, vector_store_id): file_path for file_path in pdf_files}\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(pdf_files)):\n",
    "            result = future.result()\n",
    "            if result[\"status\"] == \"success\":\n",
    "                stats[\"successful_uploads\"] += 1\n",
    "            else:\n",
    "                stats[\"failed_uploads\"] += 1\n",
    "                stats[\"errors\"].append(result)\n",
    "\n",
    "    return stats\n",
    "\n",
    "def create_vector_store(store_name: str) -> dict:\n",
    "    try:\n",
    "        vector_store = client.vector_stores.create(name=store_name)\n",
    "        details = {\n",
    "            \"id\": vector_store.id,\n",
    "            \"name\": vector_store.name,\n",
    "            \"created_at\": vector_store.created_at,\n",
    "            \"file_count\": vector_store.file_counts.completed\n",
    "        }\n",
    "        print(\"Vector store created:\", details)\n",
    "        return details\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating vector store: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created: {'id': 'vs_67d856191edc8191a8cf9580b57aac27', 'name': 'mediterranean_noir_store', 'created_at': 1742231065, 'file_count': 0}\n",
      "13 PDF files to process. Uploading in parallel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  5.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_files': 13,\n",
       " 'successful_uploads': 13,\n",
       " 'failed_uploads': 0,\n",
       " 'errors': []}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_name = \"mediterranean_noir_store\"\n",
    "vector_store_details = create_vector_store(store_name)\n",
    "upload_pdf_files_to_vector_store(vector_store_details[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message):\n",
    "    query = message\n",
    "    response = client.responses.create(\n",
    "        input= query,\n",
    "        instructions=\"Answer the question with as much detail as you can.\",\n",
    "        model=\"gpt-4o-mini\",\n",
    "        tools=[{\n",
    "            \"type\": \"file_search\",\n",
    "            \"vector_store_ids\": [vector_store_details['id']],\n",
    "        }]\n",
    "    )\n",
    "    # Extract annotations from the response\n",
    "    annotations = response.output[1].content[0].annotations\n",
    "    \n",
    "    # Get top-k retrieved filenames\n",
    "    retrieved_files = set([result.filename for result in annotations])\n",
    "\n",
    "    answer = f'Files used: {retrieved_files}' + '\\n' + 'Response:' + response.output[1].content[0].text\n",
    "\n",
    "    return answer\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(fn=chat, inputs=\"textbox\", outputs=\"textbox\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
